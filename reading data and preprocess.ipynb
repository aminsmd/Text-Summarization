{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cat,n):\n",
    "    sent = []\n",
    "    for i in range(1,int(n)+1):\n",
    "        if(i<10):\n",
    "            ad = \"00\" + str(i)\n",
    "        elif(i<100):\n",
    "            ad = \"0\" + str(i)\n",
    "        elif(cat==\"sport\" and i==199): #error openning the file\n",
    "            continue\n",
    "        else:\n",
    "            ad = str(i)\n",
    "        f = open(\"BBC News Summary/News Articles/\"+ cat +\"/\"+ad+\".txt\")\n",
    "        n = \"\"\n",
    "        for line in f: \n",
    "            n += line\n",
    "        sent.append(n)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(cat_sent):\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    for i in cat_sent:\n",
    "        a = []\n",
    "        for j in sent_tokenize(i):\n",
    "            c = []\n",
    "            for k in word_tokenize(j):\n",
    "                if k not in stop_words:\n",
    "                    c.append(k)\n",
    "            a.append(c)\n",
    "        b.append(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading data, tokenizing and saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = []\n",
    "sports = read_data(\"sport\",511)\n",
    "t = tokenizer(sports)\n",
    "f = open(\"BBC News Summary/News Articles/sport/dumps/sport_tokenized_sentences\",\"wb\")\n",
    "pk.dump(t,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "business = []\n",
    "business = read_data(\"business\",510)\n",
    "t = tokenizer(business)\n",
    "f = open(\"BBC News Summary/News Articles/business/dumps/business_tokenized_sentences\",\"wb\")\n",
    "pk.dump(t,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainment = []\n",
    "entertainment = read_data(\"entertainment\",386)\n",
    "t = tokenizer(entertainment)\n",
    "f = open(\"BBC News Summary/News Articles/entertainment/dumps/entertainment_tokenized_sentences\",\"wb\")\n",
    "pk.dump(t,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics = []\n",
    "politics = read_data(\"politics\",417)\n",
    "t = tokenizer(politics)\n",
    "f = open(\"BBC News Summary/News Articles/politics/dumps/politics_tokenized_sentences\",\"wb\")\n",
    "pk.dump(t,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = []\n",
    "tech = read_data(\"tech\",401)\n",
    "t = tokenizer(tech)\n",
    "f = open(\"BBC News Summary/News Articles/tech/dumps/tech_tokenized_sentences\",\"wb\")\n",
    "pk.dump(t,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word to vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "embeddings_size = 100\n",
    "i = 0\n",
    "with open('glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        if i > 400000:\n",
    "            break\n",
    "        i += 1\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = [float(i) for i in values[1:]]\n",
    "        embeddings_index[word] = coefs\n",
    "embeddings_index['<PAD>'] = [0] * 100\n",
    "embeddings_index['<UNK>'] = [1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_embedding(cat):\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in cat:\n",
    "        embedding = np.zeros(100)\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                if k not in embeddings_index:\n",
    "                    k = np.zeros(100)\n",
    "                else:\n",
    "                    embedding += np.array(embeddings_index[k])\n",
    "            e = embedding/len(j)\n",
    "            b.append(e)\n",
    "        a.append(b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = sent_embedding(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
